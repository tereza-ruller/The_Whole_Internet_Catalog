Web crawler
A Web crawler is an Internet bot that systematically browses the World Wide Web, typically for the purpose of Web indexing.
A Web crawler may also be called a Web spider,[1] an ant, an automatic indexer,[2] or (in the FOAF software context) a Web scutter.[3]
Web search engines and some other sites use Web crawling or spidering software to update their web content or indexes of others sites' web content. Web crawlers can copy all the pages they visit for later processing by a search engine that indexes the downloaded pages so that users can search them much more quickly.
Crawlers can validate hyperlinks and HTML code. They can also be used for web scraping (see also data-driven programming).

*http://en.wikipedia.org/wiki/Web_crawler
